{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea5599-3c2d-470a-aad8-3d922eb73f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m143.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m145.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed fsspec-2024.6.0 huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting imageio\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.24.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.3.0)\n",
      "Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imageio\n",
      "Successfully installed imageio-2.34.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2024.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.27.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.27.1-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-5.27.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install imageio\n",
    "!pip install accelerate\n",
    "!pip install sentencepiece\n",
    "!pip install protobuf\n",
    "import datetime\n",
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from transformers import MistralForCausalLM, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ada2c28-8850-4697-8a7f-c0be82145a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cd3acf5b22408fae0e7621d7b6725f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edd88d13-0aa4-46bd-ae10-a3fff720c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_0 = \"cuda:0\"\n",
    "model_folder = \"valine/OpenPirate\"  # name of the model\n",
    "image_output_folder = \"/workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d64992f-c744-4121-8727-30ca4db1d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个名为 main 的函数，用于加载一个预训练的语言模型和分词器，生成嵌入结果，并调用前面定义的函数来可视化这些嵌入结果\n",
    "#该 main 函数执行以下步骤：\n",
    "  #加载预训练模型的配置、模型和分词器\n",
    "  #定义一个字符串 probe_string，用于生成嵌入结果\n",
    "  #计算 probe_string 的嵌入结果，并将其存储在 probe_results 列表中\n",
    "  #调用 plot_embedding_flow 函数，对嵌入结果进行可视化，并生成一个 GIF 动图\n",
    "\n",
    "def main():\n",
    "    #从 model_folder 中加载预训练模型的配置 config\n",
    "    config = AutoConfig.from_pretrained(model_folder)\n",
    "    \n",
    "    #加载一个名为 MistralForCausalLM 的预训练语言模型 mistral\n",
    "      #model_folder：模型存储的文件夹路径。\n",
    "      #torch_dtype=torch.float16：指定模型使用 16 位浮点数\n",
    "      #device_map=device_0：指定模型加载到的设备（例如 GPU）\n",
    "      #use_flash_attention_2=False：禁用 Flash Attention 2\n",
    "      #config=config：使用之前加载的配置\n",
    "    mistral = MistralForCausalLM.from_pretrained(\n",
    "        model_folder,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=device_0,\n",
    "        use_flash_attention_2=False,\n",
    "        config=config, )\n",
    "\n",
    "    #从 model_folder 中加载预训练分词器 tokenizer. trust_remote_code=True：信任远程代码以允许自定义分词器的代码执行\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_folder, trust_remote_code=True)\n",
    "\n",
    "    # The last token of this string will be used to generate the image\n",
    "    # 定义一个用于生成嵌入结果的字符串 probe_string\n",
    "    probe_string = \"Put a sample string here\"\n",
    "\n",
    "    # Probe results is an array so that you can plot the changes to the\n",
    "    # output over time. The plot_embedding_flow will generate an animated gif.\n",
    "    # Call compute_model_output multiple times and append the results to\n",
    "    # probe_results.\n",
    "    # 初始化一个空列表 probe_results，用于存储不同时间步的嵌入结果\n",
    "     # 调用 compute_model_output 函数计算 probe_string 的嵌入结果，并将其添加到 probe_results 中\n",
    "     # mistral：预训练语言模型\n",
    "     # tokenizer：预训练分词器\n",
    "     # probe_string：用于生成嵌入结果的字符串\n",
    "    probe_results = []\n",
    "    probe_result = compute_model_output(mistral, tokenizer, probe_string)\n",
    "    probe_results.append(probe_result)\n",
    "\n",
    "    # 调用 plot_embedding_flow 函数，对生成的嵌入结果进行可视化，并生成一个 GIF 动图\n",
    "    # probe_results：包含所有嵌入结果的列表\n",
    "    plot_embedding_flow(probe_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc6c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个名为 compute_model_output 的函数，该函数用于计算一个基于预训练语言模型的输出\n",
    "\n",
    "def compute_model_output(base_model, tokenizer, ground_truth):\n",
    "    # 使用 no_grad() 上下文管理器，在计算过程中不计算梯度，减少内存使用\n",
    "    with torch.no_grad():\n",
    "        #用于存储每层的输出\n",
    "        layer_output = [] \n",
    "\n",
    "        # 使用 tokenizer 对 ground_truth 进行编码，生成 PyTorch 张量, 并将结果存储在 input_ids 中\n",
    "        encoding = tokenizer(ground_truth, return_tensors=\"pt\")\n",
    "        input_ids = encoding['input_ids'].to(device_0)\n",
    "\n",
    "        # 获取输入的词嵌入（embedding）,使用模型的嵌入层 embed_tokens 将 input_ids 转换为词嵌入 hidden_states\n",
    "        hidden_states = base_model.model.embed_tokens(input_ids)\n",
    "\n",
    "        # 获取序列长度和批次大小\n",
    "        sequence_length = hidden_states.shape[1]\n",
    "        batch_size = hidden_states.shape[0]\n",
    "\n",
    "        # 创建一个表示位置编码的张量 position_ids，其形状为 (1, sequence_length), 使用 expand 方法将其扩展为 (batch_size, sequence_length)\n",
    "        position_ids = torch.arange(sequence_length, device=device_0).unsqueeze(0)\n",
    "        position_ids = position_ids.expand(batch_size, -1)\n",
    "\n",
    "        # 创建一个上三角矩阵 attention_mask，用于掩码未来的 token，其形状为 (sequence_length, sequence_length)\n",
    "        # 使用 unsqueeze 方法将其形状扩展为 (1, 1, sequence_length, sequence_length)\n",
    "        attention_mask = torch.triu(torch.full(\n",
    "            (sequence_length, sequence_length), float('-inf')), diagonal=1)\n",
    "        attention_mask = attention_mask.to(device_0)\n",
    "        attention_mask = attention_mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # 遍历模型的每一层，计算每层的输出\n",
    "        # 调用每层的 forward 方法，传入 hidden_states、attention_mask 和 position_ids\n",
    "        # 将每层的输出 hidden_states 添加到 layer_output 列表中\n",
    "        for layer in base_model.model.layers:\n",
    "            output = layer(hidden_states,\n",
    "                           attention_mask=attention_mask,\n",
    "                           position_ids=position_ids,\n",
    "                           output_attentions=True)\n",
    "            hidden_states = output[0]\n",
    "            layer_output.append(hidden_states)\n",
    "        return layer_output  #返回存储所有层输出的列表 layer_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb29fd9-91b0-475e-a785-a29a8f867026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个函数 vectorized_get_color_rgb，它将一个取值在 [0, max_value] 区间的张量转换为 RGB 颜色表示\n",
    "#这段代码实现了将归一化的 HSV 颜色值转换为 RGB 颜色值的功能\n",
    "\n",
    "def vectorized_get_color_rgb(value_tensor, max_value=1.0):\n",
    "    #h是归一化后的 value_tensor，范围为 [0, 1]\n",
    "    h = (value_tensor * 1.0) / max_value  \n",
    "    # s 和 v 被初始化为与 h 形状相同且值全为1的张量，表示饱和度和亮度均为1\n",
    "    s = torch.ones_like(h)  \n",
    "    v = torch.ones_like(h)\n",
    "    \n",
    "    # c 是颜色值，根据 HSV 色彩模型中的公式 c = v * s 计算\n",
    "    # x 是中间值，用于计算 RGB 值\n",
    "    # m 是最小值，用于计算最终的 RGB 值\n",
    "    c = v * s\n",
    "    x = c * (1 - torch.abs((h * 6) % 2 - 1))\n",
    "    m = v - c\n",
    "    \n",
    "    # h1 用于确定颜色所在的区间\n",
    "    h1 = (h * 6).int()\n",
    "    \n",
    "    #使用 torch.stack 将三个通道（R、G、B）的值合并在一起，生成一个 RGB 张量\n",
    "    #对每个通道，根据 h1 的值确定使用 c、x 还是 0：\n",
    "     #红色通道：当 h1 为 0 或 5 时，值为 c；当 h1 为 1 或 4 时，值为 x；否则为 0\n",
    "     #绿色通道：当 h1 为 1 或 2 时，值为 c；当 h1 为 0 或 3 时，值为 x；否则为 0\n",
    "     #蓝色通道：当 h1 为 3 或 4 时，值为 c；当 h1 为 2 或 5 时，值为 x；否则为 0\n",
    "    #将 m 加到每个通道上，调整亮度\n",
    "    rgb = torch.stack((\n",
    "        torch.where((h1 == 0) | (h1 == 5), c, torch.where((h1 == 1) | (h1 == 4), x, 0)),\n",
    "        torch.where((h1 == 1) | (h1 == 2), c, torch.where((h1 == 0) | (h1 == 3), x, 0)),\n",
    "        torch.where((h1 == 3) | (h1 == 4), c, torch.where((h1 == 2) | (h1 == 5), x, 0)),\n",
    "    ), dim=-1) + m.unsqueeze(-1)\n",
    "\n",
    "    return rgb  #返回计算得到的 RGB 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0761f0a4-4d56-4e4c-83bf-7a6b013281f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个函数 generate_filename，用于生成包含当前时间戳的文件名\n",
    "#prefix：文件名前缀  extension：文件扩展名\n",
    "\n",
    "def generate_filename(prefix, extension): \n",
    "    #获取当前日期和时间\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    #将 current_time 格式化为 \"年-月-日_时-分-秒\" 格式\n",
    "    formatted_time = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    #生成的文件名格式为 \"前缀_格式化时间.扩展名\"\n",
    "    filename = f\"{prefix}_{formatted_time}.{extension}\"\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f391f3-57bf-400f-85b0-d7355550eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个名为 plot_layers 的函数，该函数将多个层的嵌入结果可视化，并生成一个包含这些结果的 GIF 动图\n",
    "#该函数将多个层的嵌入结果转换为 RGB 图像，并将这些图像生成一个 GIF 动图\n",
    "#在生成过程中，对数据进行归一化处理，并使用填充和分割技术将张量转换为图像\n",
    "#最终返回生成的 GIF 动图的文件路径\n",
    "\n",
    "#定义一个函数 plot_layers，接收四个参数：\n",
    "  #all_words：一个包含所有层嵌入结果的列表。\n",
    "  #title：生成文件的标题前缀。\n",
    "  #file_path：保存图像和 GIF 的文件路径。\n",
    "  #normalize：一个布尔值，指示是否对数据进行归一化处理，默认值为 True\n",
    "def plot_layers(all_words, title, file_path, normalize=True):\n",
    "    #获取序列长度 sequence_length，并初始化一个空列表 paths 用于存储每张图像的路径\n",
    "    sequence_length = all_words[0].shape[1]\n",
    "    paths = []\n",
    "    \n",
    "    #将 all_words 中的所有张量沿第一个维度拼接，形成一个大的张量 all_words_cat\n",
    "    #计算拼接后的张量的全局最小值 global_min_val 和全局最大值 global_max_val\n",
    "    #计算全局均值 global_mean 和全局方差 global_var，并将方差乘以 25 以扩展其范围\n",
    "    all_words_cat = torch.cat(all_words, dim=0)\n",
    "    global_min_val = torch.min(all_words_cat)\n",
    "    global_max_val = torch.max(all_words_cat)\n",
    "    global_mean = torch.mean(all_words_cat)\n",
    "    global_var = torch.var(all_words_cat) * 25\n",
    "\n",
    "    #如果需要归一化处理，则设置 min_val 和 max_val 为均值减去/加上方差的范围\n",
    "    #否则，设置 min_val 和 max_val 为全局最小值和最大值\n",
    "    if normalize:\n",
    "        min_val = global_mean - global_var\n",
    "        max_val = global_mean + global_var\n",
    "    else:\n",
    "        min_val = global_min_val\n",
    "        max_val = global_max_val\n",
    "        \n",
    "    #外层 for 循环遍历序列的每个时间步 i\n",
    "    for i in range(sequence_length):\n",
    "        \n",
    "        #初始化一个空列表 list_of_tensors，用于存储当前时间步的所有嵌入结果。\n",
    "        list_of_tensors = []\n",
    "        \n",
    "        #内层 for 循环遍历 all_words 中的每个张量，从每个张量中提取第 i 个时间步的嵌入结果，并添加到 list_of_tensors 中\n",
    "        for tensor in all_words:\n",
    "            list_of_tensors.append(tensor[:, i, :])\n",
    "        \n",
    "        # 将 list_of_tensors 中的所有张量沿第一个维度拼接，形成一个大的张量 full_tensor\n",
    "        # 设置图像的高度 height 为 512 像素\n",
    "        # Step 1: Concatenate tensors along width\n",
    "        full_tensor = torch.cat(list_of_tensors, dim=0)  # Shape: [1, 4096 * 31]\n",
    "        height = 512\n",
    "        \n",
    "        #将 full_tensor 沿第二个维度分割成多个块，每个块的宽度为 height\n",
    "        #使用 F.pad 函数对每个块进行填充，使其宽度达到 height，填充值为 max_val\n",
    "        #将这些填充后的块沿第一个维度拼接，形成一个新的张量 reshaped_tensor，并取其绝对值\n",
    "        tensor_split = [F.pad(t, (0, max(0, height - t.shape[1])),\n",
    "                              'constant', max_val.item()) for t in\n",
    "                        torch.split(full_tensor, height, dim=1)]\n",
    "        reshaped_tensor = torch.cat(tensor_split, dim=0)\n",
    "        reshaped_tensor = torch.abs(reshaped_tensor)\n",
    "\n",
    "        # Normalize data\n",
    "        # 对 reshaped_tensor 进行归一化处理，使其值在 [0, 1] 范围内\n",
    "        # 调用 vectorized_get_color_rgb 函数，将归一化后的数据转换为 RGB 颜色表示\n",
    "        normalized_data = (reshaped_tensor - min_val) / (max_val - min_val)\n",
    "        color_tensor = vectorized_get_color_rgb(normalized_data)\n",
    "\n",
    "        # Generate image\n",
    "        # 将 color_tensor 转换为 NumPy 数组，并将其值缩放到 [0, 255] 范围，数据类型转换为 uint8\n",
    "        #使用 Image.fromarray 函数将 NumPy 数组转换为图像对象 image\n",
    "        array = (color_tensor.cpu().numpy() * 255).astype(np.uint8)\n",
    "        image = Image.fromarray(array, 'RGB')\n",
    "\n",
    "        # Save the image\n",
    "        #生成临时文件名 tmp_name。\n",
    "        #调用 generate_filename 函数生成图像文件名 filename。\n",
    "        #将图像文件保存到指定路径 full_path。\n",
    "        #将 full_path 添加到 paths 列表中。\n",
    "        tmp_name = \"raw_values_tmp\" + str(i)\n",
    "        filename = title + \"_\" + generate_filename(tmp_name + str(i), \"png\")\n",
    "        full_path = os.path.join(file_path, filename)\n",
    "        image.save(full_path)\n",
    "        paths.append(full_path)\n",
    "\n",
    "    # Create gif from images\n",
    "    # 生成 GIF 文件名 filename\n",
    "    # 使用 imageio.get_writer 函数创建一个 GIF 写入对象 writer，设置帧率 fps 为 15，循环次数 loop 为 0\n",
    "    # 遍历 paths 列表，读取每个图像文件，并将其添加到 GIF 中\n",
    "    filename = title + \"_\" + generate_filename(\"layers\", \"gif\")\n",
    "    gif_path = os.path.join(file_path, filename)\n",
    "    with imageio.get_writer(gif_path, mode='I', fps=15, loop=0) as writer:\n",
    "        for filename in paths:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Remove temporary files\n",
    "    # 遍历 paths 列表，删除所有临时图像文件\n",
    "    for filename in paths:\n",
    "        os.remove(filename)\n",
    "\n",
    "    # open_image(gif_path)\n",
    "    # 返回生成的 GIF 文件路径 gif_path\n",
    "    return gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0cadace-7c82-4cfc-8fc2-fc26d38963ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这段代码定义了一个名为 plot_embedding_flow 的函数，用于处理和可视化多个层的嵌入结果\n",
    "#该函数从 probe_results 中提取每一层的嵌入结果，并将其组织成一个新的张量列表\n",
    "#通过 plot_layers 函数将这些嵌入结果可视化，并返回生成图像的路径\n",
    "\n",
    "#定义一个函数 plot_embedding_flow，接收一个参数 probe_results，该参数包含多个层的嵌入结果\n",
    "def plot_embedding_flow(probe_results):\n",
    "    #计算 probe_results 中每个结果包含的层数\n",
    "    layer_count = len(probe_results[0])\n",
    "    \n",
    "    #初始化一个空列表 layer_embeddings，用于存储每一层的嵌入结果\n",
    "    layer_embeddings = []\n",
    "    \n",
    "    #外层 for 循环遍历所有层\n",
    "    for l_index in range(layer_count):\n",
    "        \n",
    "        #初始化一个空列表 sequence_embedding，用于存储当前层的所有嵌入结果\n",
    "        sequence_embedding = []\n",
    "        \n",
    "        #内层 for 循环遍历 probe_results 中的每个结果\n",
    "        #从 probe_result 中提取当前层 l_index 的最后一个时间步的嵌入结果，并将其添加到 sequence_embedding 中\n",
    "        for probe_result in probe_results:\n",
    "            embedding = probe_result[l_index][:, -1, :]\n",
    "            sequence_embedding.append(embedding)\n",
    "            \n",
    "        #将 sequence_embedding 列表堆叠为一个张量 layer_embedding，其维度为 (序列长度, 批次大小, 嵌入维度)\n",
    "        layer_embedding = torch.stack(sequence_embedding, dim=1)\n",
    "        layer_embeddings.append(layer_embedding)\n",
    "    \n",
    "    #调用 plot_layers 函数对当前进度进行可视化\n",
    "      #layer_embeddings：包含所有层嵌入结果的列表\n",
    "      #\"probe_results\"：用于标记图像的标签\n",
    "      #image_output_folder：图像输出文件夹的路径\n",
    "    # Plot current progress\n",
    "    path = plot_layers(layer_embeddings, \"probe_results\", image_output_folder)\n",
    "    return path #返回可视化图像的保存路径\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5f91f0-7981-4927-b911-1bca6f4d8185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa016f00e971411ea4c86e6efbc311b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/tmp/ipykernel_229/71677521.py:90: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filename)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62cd86-d3d3-4b1b-8e6a-97dae2fdf794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
